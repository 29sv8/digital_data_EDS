{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875be184-70cc-4e08-937c-22a2ab79c6a9",
   "metadata": {},
   "source": [
    "## Testing of methods written for the file_handling_methods.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4318f578-77c9-460a-a555-09fd265032e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # import os system module so that we can use its functions to e.g. check directory contents\n",
    "start_path = (\"C:/Users/svreugdenhil/OneDrive - NIOZ/Documenten/GitHub/\") # start of the path all my files are located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ac898-8521-40d7-8cb4-aeb3569d523d",
   "metadata": {},
   "source": [
    "#### URL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631bb6c3-2add-450b-ad3e-298aa9a3483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_url_a(url, filename):\n",
    "    \"\"\"\n",
    "    Description\n",
    "        ----\n",
    "        This function uses the urllib.request module that is included in Python \n",
    "        (version 3.10.9) to download a file from a given URL link. The file is \n",
    "        downloaded into the current working directory if only a filename is \n",
    "        provided, or into a specified exisiting directory (absolute or relative \n",
    "        filepath). \n",
    "        This function was tested in a Jupyter notebook.\n",
    "        ----\n",
    "    Parameters\n",
    "        ----\n",
    "        url\n",
    "            >> the url link from which to download the file\n",
    "        filename\n",
    "            >> the name the file is to be called in the current working \n",
    "            directory\n",
    "            >> OR a filepath (absolute or relative) of an existing folder \n",
    "    Returns\n",
    "        ----\n",
    "        urllib.request.urlretrieve returns a tuple of the filename and some \n",
    "        information.\n",
    "        out\n",
    "            >> the filename\n",
    "        response\n",
    "            >> the information\n",
    "        Prints the message that the file was downloaded succesfully and the \n",
    "        information and downloads the file in the current working directory (\n",
    "        if only the filename was specified) or the directory that was \n",
    "        specified.\n",
    "        ----\n",
    "    Versioning\n",
    "        ----\n",
    "        Python: 3.10.9\n",
    "        urllib included in Python version\n",
    "        ----\n",
    "    \"\"\"\n",
    "    import urllib.request\n",
    "    # store tuple outcome of urlretrieve into 2 variables:\n",
    "    out, response = urllib.request.urlretrieve(url, filename) \n",
    "    print(f\"Successfully downloaded {out}\\n\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "457e1123-0166-480c-8e92-d862d00f7f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded test_files/hancock.zip\n",
      "\n",
      "Connection: close\n",
      "Content-Length: 17341\n",
      "Cache-Control: max-age=300\n",
      "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
      "Content-Type: application/zip\n",
      "ETag: \"27b48bb2069d369cf9e3265594d6b9733ee524ee3298ad109e17773a2bf5387a\"\n",
      "Strict-Transport-Security: max-age=31536000\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: deny\n",
      "X-XSS-Protection: 1; mode=block\n",
      "X-GitHub-Request-Id: 6EAC:0E20:21888BA:22F11B3:660588F3\n",
      "Accept-Ranges: bytes\n",
      "Date: Thu, 28 Mar 2024 15:16:27 GMT\n",
      "Via: 1.1 varnish\n",
      "X-Served-By: cache-ams21040-AMS\n",
      "X-Cache: HIT\n",
      "X-Cache-Hits: 1\n",
      "X-Timer: S1711638987.445082,VS0,VE1\n",
      "Vary: Authorization,Accept-Encoding,Origin\n",
      "Access-Control-Allow-Origin: *\n",
      "Cross-Origin-Resource-Policy: cross-origin\n",
      "X-Fastly-Request-ID: 1e434e7d23ea6dcc4823f646f3fde44b3131f7ff\n",
      "Expires: Thu, 28 Mar 2024 15:21:27 GMT\n",
      "Source-Age: 215\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define URL\n",
    "url = \"https://github.com/PacktPublishing/Learning-Geospatial-Analysis-with-Python-Fourth-Edition/raw/main/B19730_02_Asset_Files/hancock.zip\"\n",
    "# Define filename\n",
    "filename = \"test_files/hancock.zip\" \n",
    "\n",
    "# Download file\n",
    "download_from_url_a(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a7ed13-5898-4bf6-b29a-8ed5260f4dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'hancock.zip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"{start_path}/digital_data_EDS/test_files\") # check if files are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dba1846-72e0-4a31-9b1d-f8209bc50725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_url_b(url, filename):\n",
    "    \"\"\"\n",
    "    IMPORTANT NOTE: \n",
    "    download requests module into your environment before using this function\n",
    "    Description\n",
    "        ----\n",
    "        This function uses the requests module to download a file from a given \n",
    "        URL link. The file is downloaded into the current working directory if \n",
    "        only a filename is provided, or into a specified existing directory\n",
    "        (absolute or relative filepath). \n",
    "        This function was tested in a Jupyter notebook.\n",
    "        ----\n",
    "    Parameters\n",
    "        ----\n",
    "        url\n",
    "            >> the url link from which to download the file\n",
    "        filename\n",
    "            >> the name the file is to be called in the current working \n",
    "            directory\n",
    "            >> OR a filepath (absolute or relative) of an existing folder\n",
    "        ----\n",
    "    Returns\n",
    "        ----\n",
    "        Prints a statement that the file was succesfully created and downloads\n",
    "        the file to the current working directory (if only filename specified)\n",
    "        or the directory that was specified.\n",
    "        ----\n",
    "    Versioning\n",
    "        ----\n",
    "        Python: 3.10.9\n",
    "        requests: 2.31.0\n",
    "        ----\n",
    "    \"\"\"\n",
    "    import requests \n",
    "    r = requests.get(url) # access url\n",
    "    # write content of the opened file into a new file:\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"The file {filename} was succesfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "780c6bd0-9dbe-48b2-802e-70f50ea35c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file test_files/hancock_2.zip was succesfully created.\n"
     ]
    }
   ],
   "source": [
    "# Define URL\n",
    "url = \"https://github.com/PacktPublishing/Learning-Geospatial-Analysis-with-Python-Fourth-Edition/raw/main/B19730_02_Asset_Files/hancock.zip\"\n",
    "# Define filename\n",
    "filename = \"test_files/hancock_2.zip\" \n",
    "\n",
    "# Download file\n",
    "download_from_url_b(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f94e7d-3d4b-4753-8db0-2202c5177b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'hancock.zip', 'hancock_2.zip']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"{start_path}/digital_data_EDS/test_files\") # check if files are present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2571e51-feaf-42eb-b2b2-94f516af3fea",
   "metadata": {},
   "source": [
    "#### FTP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536d027e-5db5-4161-b565-557be9d3c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ftp_content(\n",
    "    server, username=\"anonymous\", password=\"anonymous\", dir=\"\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Description\n",
    "        ----\n",
    "        This function uses the ftplib module that is included in Python (\n",
    "        version 3.10.9) to view the contents of a specified FTP server.\n",
    "        When accessing a public server, username and password are usually both \n",
    "        \"anonymous\". When a username and password are not provided, this \n",
    "        function automatically uses \"anonymous\" as both username and password. \n",
    "        The function makes use of an encrypted connection in order to be able \n",
    "        to access public servers. \n",
    "        If no directory is specified, the contents of the home directory of the\n",
    "        FTP server are listed, else the contents of the specified directory are\n",
    "        listed.\n",
    "        NOTE 28-03-2024: this function has NOT been tested with a non-public\n",
    "        FTP server yet!\n",
    "        ----\n",
    "    Parameters\n",
    "        ----\n",
    "        server\n",
    "            >> the address of the FTP server you are reaching\n",
    "        username (optional)\n",
    "            >> username for the FTP server, if not provided = \"anonymous\"\n",
    "        password (optional)\n",
    "            >> password for the FTP server, if not provided = \"anonymous\"\n",
    "        dir (optional)\n",
    "            >> the name or path of the directory within the FTP server\n",
    "        ----\n",
    "    Returns\n",
    "        ----\n",
    "        If no directory is specified, the function returns the listed contents \n",
    "        of the home directory of the FTP server, else it lists the contents of\n",
    "        the specified directory within the FTP server\n",
    "        ----\n",
    "    Versioning\n",
    "        ----\n",
    "        Python: 3.10.9\n",
    "        ftplib included in Python version\n",
    "    \"\"\"\n",
    "    import ftplib\n",
    "    ftp = ftplib.FTP_TLS(server)\n",
    "    ftp.login() \n",
    "    ftp.prot_p() \n",
    "    if dir != \"\":\n",
    "        ftp.cwd(dir)\n",
    "        ftp.retrlines('LIST')\n",
    "    else:\n",
    "        ftp.retrlines('LIST')\n",
    "    ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f18b72d-dc0f-4757-bb08-af774f55c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify server\n",
    "server = \"ftp.pmel.noaa.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74de3a8b-2c10-4bbe-b8c3-6ec78db6882a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxrwxr-x    9 1054     310          4096 Aug 26  2013 AD\n",
      "drwxrwxr-x   11 1054     310          4096 Nov 02  2018 CARD\n",
      "drwxrwxr-x   13 1054     310          4096 Oct 30  2014 CNSD\n",
      "drwxrwxr-x    5 1054     310          4096 Jun 05  2019 EDD\n",
      "drwxrwsr-x    8 1052     310          4096 Apr 24  2015 EPIC\n",
      "drwxr-xr-x    3 1054     310          4096 Feb 01  2011 GTMBAdata\n",
      "drwxrwxr-x    3 1054     310          4096 Sep 03  2008 NOAAServer\n",
      "drwxr-xr-x   63 1054     310          4096 Mar 15  2013 OCRD\n",
      "drwxrwxr-x    7 1054     310          4096 Nov 16  2011 OD\n",
      "drwxr-xr-x    3 1054     310          4096 Aug 05  2010 OER\n",
      "drwxr-xr-x   13 1054     310          4096 Jul 20  2020 OERD\n",
      "drwxr-xr-x    2 1054     310          4096 Feb 28  2005 PMEL\n",
      "drwxrwxr-x    6 1054     310          4096 Jul 13  2017 arctic-heat\n",
      "drwxrwxr-x    4 1054     310          4096 Aug 08  2022 asvco2\n",
      "drwxrwxr-x    5 1054     310          4096 Apr 12  2004 atlas\n",
      "drwxrwxr-x    7 1054     310          4096 Nov 07  2013 cfc\n",
      "drwxrwxr-x    4 1054     310          4096 Mar 06  1995 climatology\n",
      "drwxrwxr-x   16 1054     310          4096 Sep 28  1998 coare\n",
      "drwxrwxr-x   13 1054     310          4096 Aug 02  2012 ctd\n",
      "lrwxrwxrwx    1 1054     310             9 Mar 20  2007 epic -> EPIC/epic\n",
      "lrwxrwxrwx    1 1054     310             8 Mar 20  2007 eps -> EPIC/eps\n",
      "drwxrwxr-x    5 1054     310          4096 Jun 06  2018 ferret\n",
      "drwxrwxr-x   17 1054     310          4096 Feb 01  2023 foci\n",
      "lrwxrwxrwx    1 1054     310             9 Mar 20  2007 java -> EPIC/java\n",
      "drwxr-xr-x    7 1054     310          4096 Jun 25  2015 keodata\n",
      "drwxrwxr-x    2 1054     310          4096 Jun 07  1997 mosaic\n",
      "drwxrwxr-x    4 1054     310          4096 Dec 28  1998 netcdf\n",
      "drwxr-xr-x   20 1055     310          4096 Mar 02  2017 newport\n",
      "drwxrwxr-x    2 1054     310          4096 Feb 04  2010 ocean_climate\n",
      "drwxr-xr-x    6 1054     310          4096 Jun 25  2015 papadata\n",
      "drwxr-xr-x    2 1054     310          4096 Nov 20  2019 pco2\n",
      "dr-xr-xr-x    4 1054     310          4096 Apr 30  2007 pub\n",
      "-rw-rw-r--    1 1054     310            65 Oct 01  2004 robots.txt\n",
      "drwxr-xr-x    4 1054     310          4096 Oct 06 18:02 rudics\n",
      "drwxrwxr-x    2 1054     310          4096 Dec 22  2000 scs\n",
      "drwxrwxr-x    2 1054     310          4096 May 21  1999 shields\n",
      "lrwxrwxrwx    1 1054     310            23 Apr 30  2007 special_request -> ferret/special_request/\n",
      "drwxrwxr-x   14 1054     310          4096 Apr 30  2013 tao\n",
      "drwxrwxr-x   22 1054     310          4096 Dec 06  2019 taodata\n",
      "drwxrwxr-x   13 1054     310          4096 Jan 10  2008 taographics\n",
      "drwxrwxr-x   59 1054     310          4096 Aug 10  2022 tsunami\n",
      "drwxrwxr-x    4 1054     310          4096 Sep 30  2016 uwpCO2\n",
      "drwxrwxr-x   13 1054     310          4096 Oct 24  2019 vents\n",
      "drwxrwxr-x    2 1054     310          4096 Jun 30  2014 video\n",
      "drwxrwxr-x    4 1054     310          4096 Sep 23  2010 wocecfc\n",
      "drwxrwxr-x    2 1054     310          4096 Mar 20  2023 wrclib\n"
     ]
    }
   ],
   "source": [
    "check_ftp_content(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf2ff6e-8e61-4949-b5a0-19bf7e00a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x    2 1054     310          4096 Jun 12  2001 anderson\n",
      "drwxrwxr-x   25 1054     310          4096 Jun 07  2018 graphics\n",
      "drwxrwxr-x    5 1054     310          4096 Sep 09  2010 ryan\n",
      "drwxrwxr-x    2 1054     310          4096 Aug 26  2013 sandra\n",
      "drwxr-xr-x    4 1054     310          4096 Mar 11  1998 sim\n",
      "drwxr-xr-x    2 1054     310          4096 Nov 12  2014 tracey\n",
      "drwxr-xr-x    2 1054     310          4096 Jun 05  2006 tsu_res\n"
     ]
    }
   ],
   "source": [
    "check_ftp_content(server, dir=\"AD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5372ba2-d916-412f-ba13-f47315490b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x    2 1054     310          4096 May 21  2003 spillane\n",
      "drwxr-xr-x    2 1054     310          4096 Sep 09  2010 tsunami_forecast_reports\n",
      "drwxr-xr-x    2 1054     310          4096 Jun 28  2010 tsunami_hazard_assessment\n"
     ]
    }
   ],
   "source": [
    "check_ftp_content(server, dir=\"AD/ryan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d29c53c-8204-48c6-87de-fb13e9f0cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_from_ftp(\n",
    "    server, dir, filename, username=\"anonymous\", password=\"anonymous\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Description\n",
    "        ----\n",
    "        This function uses the ftplib module that is included in Python (\n",
    "        version 3.10.9) to download a specific file from a FTP server. The file\n",
    "        is always downloaded to the current working directory, it is not \n",
    "        possible to specify a directory.\n",
    "        When dowloading files from a public server, username and password are\n",
    "        usually both \"anonymous\". When a username and password are not provided,\n",
    "        this function automatically uses \"anonymous\" as both username and\n",
    "        password. The function makes use of an encrypted connection in order\n",
    "        to be able to download from public servers.\n",
    "        NOTE 28-03-2024: this function has NOT been tested with a non-public\n",
    "        FTP server yet!\n",
    "        ----\n",
    "    Parameters\n",
    "        ----\n",
    "        server\n",
    "            >> the address of the FTP server you are reaching\n",
    "        dir\n",
    "            >> the name of the directory in which the file(s) you are \n",
    "            downloading is located (can ba a path)\n",
    "        filename\n",
    "            >> the name of the file that you are downloading\n",
    "        username\n",
    "            >> username for the FTP server, if not provided = \"anonymous\"\n",
    "        password\n",
    "            >> password for the FTP server, if not provided = \"anonymous\"\n",
    "        ----\n",
    "    Returns\n",
    "        ----\n",
    "        Prints a statement that the file was succesfully downloaded and \n",
    "        downloads the file to the current working directory.\n",
    "        ----\n",
    "    Versioning\n",
    "        ----\n",
    "        Python: 3.10.9\n",
    "        ftplib included in Python version\n",
    "        ----\n",
    "    \"\"\"\n",
    "    import ftplib \n",
    "    ftp = ftplib.FTP_TLS(server) # access server through encrypted session\n",
    "    ftp.login(username, password) # login on server\n",
    "    ftp.prot_p() # explicitely call for protected transfer\n",
    "    ftp.cwd(dir) # go to the directory of the file\n",
    "    # Download the file \n",
    "    with open(filename, \"wb\") as out:\n",
    "        ftp.retrbinary(f\"RETR {filename}\", out.write)\n",
    "    ftp.quit() # quit the ftp server\n",
    "    print(f\"The file {filename} was succesfully downloaded.\")\n",
    "    print(f\"This is out: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb4bcc1-9a13-417d-ba7a-29d4c76ac4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "server = \"ftp.pmel.noaa.gov\"\n",
    "dir = \"taodata\"\n",
    "filename = \"taobuoypos.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23f8b46-50ca-4f83-a0d5-011832eacc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file taobuoypos.dat was succesfully downloaded.\n",
      "This is out: <_io.BufferedWriter name='taobuoypos.dat'>\n"
     ]
    }
   ],
   "source": [
    "# Call function\n",
    "file_from_ftp(server, dir, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b33151ba-a562-4ffe-817a-cf9d2df1c7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitattributes',\n",
       " '.ipynb_checkpoints',\n",
       " 'file_handling_methods.py',\n",
       " 'file_handling_methods_testing.ipynb',\n",
       " 'LICENSE',\n",
       " 'list_of_handy_modules.md',\n",
       " 'README.md',\n",
       " 'taobuoypos.dat',\n",
       " 'test_files']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"{start_path}/digital_data_EDS/\") # check if files are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7161c49a-47c5-4737-b3b1-89289f94b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buoy DM467A is located at 8 03.1N 94 55.2W\n"
     ]
    }
   ],
   "source": [
    "# Read into the file\n",
    "with open(filename) as tao:\n",
    "    buoy = tao.readlines() [5]\n",
    "    loc = buoy.split()\n",
    "    print(\"Buoy \" + str(loc[0]) + \" is located at \" + str(' '.join(loc[4:8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3c4bb6-6ccc-4c2a-9b8a-c5338bb260c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'hancock.zip', 'hancock_2.zip', 'taobuoypos.dat']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.rename(filename, f\"test_files/{filename}\")\n",
    "os.listdir(f\"{start_path}/digital_data_EDS/test_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59cc2fe-cf1f-4192-a976-2999253446fc",
   "metadata": {},
   "source": [
    "#### ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f27d91-0294-4dc0-a9df-0979eb811cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(file):\n",
    "    \"\"\"\n",
    "    Description\n",
    "        ----\n",
    "        This function uses the zipfile module that is included in Python (\n",
    "        version 3.10.9) to extact files from a zip. This function extracts\n",
    "        the files from the zip and places them into the current working \n",
    "        directory. This function then uses the the build-in os module to \n",
    "        create a new directory and move the files into that new directory.\n",
    "        The only thing that it needs to work is the path to the zipfile.\n",
    "        ----\n",
    "    Parameters\n",
    "        ----\n",
    "        file\n",
    "            >> the path to the zipfile\n",
    "        ----\n",
    "    Returns\n",
    "        ----\n",
    "        Creates a folder into the current working directory with the files \n",
    "        from the zip.\n",
    "        ----\n",
    "    Versioning\n",
    "        ----\n",
    "        Python: 3.10.9\n",
    "        zipfile included in Python version\n",
    "        os included in Python version\n",
    "        ----\n",
    "    \"\"\"\n",
    "    import zipfile # import module for opening zip files\n",
    "    import os      # import os to create a new directory to append zipfiles to\n",
    "    \n",
    "    zip = open(file, \"rb\")          # open the zipfile \n",
    "    zipShape = zipfile.ZipFile(zip) # read the zipfile\n",
    "    \n",
    "    files = [] # create a list to append files from inside the zip to\n",
    "    \n",
    "    for filename in zipShape.namelist(): # obtain filenames and give them to the files inside the zip\n",
    "        filename = f\"{filename}\"             # get actual filename\n",
    "        out = open(filename, \"wb\")  \n",
    "        out.write(zipShape.read(filename))\n",
    "        out.close()\n",
    "        files.append(filename)               # append filenames to the list\n",
    "    \n",
    "    folder_name = filename.split(\".\")[0] # create a foldername form the beginning of the filename\n",
    "    os.mkdir(folder_name)                # create a new folder\n",
    "    for file in files:\n",
    "        os.rename(f\"{file}\", f\"{folder_name}/{file}\") # move the files to the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71bad8fa-b544-4758-aa51-0a804d2ff930",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"hancock.zip\"\n",
    "extract_zip(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195365da-f491-42ec-b759-c87f7186f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitattributes',\n",
       " '.ipynb_checkpoints',\n",
       " 'file_handling_methods.py',\n",
       " 'file_handling_methods_testing.ipynb',\n",
       " 'hancock',\n",
       " 'LICENSE',\n",
       " 'list_of_handy_modules.md',\n",
       " 'README.md',\n",
       " 'test_files']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"{start_path}/digital_data_EDS/\") # check if files are present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5074edb-d504-4d42-aef7-14aba7412126",
   "metadata": {},
   "source": [
    "#### TAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da096a13-913d-4dd8-9cec-f27043ea42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_tar_gz(files, tar_name, dir_path=\"\"):\n",
    "    \"\"\"Description\n",
    "        ----\n",
    "        This function uses the tarfile module that is included in Python (\n",
    "        version 3.10.9) to create a tar archive with given files. To do so\n",
    "        it uses the w:gz mode for gzipped compression. The names of the files\n",
    "        need to be provided in a list, and the to be name of the archive must\n",
    "        be provided as well. If files in the current working directory need to \n",
    "        be archived and compressed, a dir_path should not be provided. If files\n",
    "        in another directory need to be archived, you do need to provide a path.\n",
    "        An alternative for providing a dir_path, is providing the filenames as a path.\n",
    "        (e.g. [\"hancock/hancock.dbf\", \"hancock/hancock.shp\", \"hancock/hancock/shx\"], \n",
    "        note that this way is not officially tested but should work nonetheless)\n",
    "        Please note that the new compressed archive file is always created in the\n",
    "        current working directory. \n",
    "        ----\n",
    "    Parameters\n",
    "        ----\n",
    "        files\n",
    "            >> a list of file names (or paths) that need to be archived and compressed\n",
    "        tar_name\n",
    "            >> the name of the new tar.gz file, provide the name without the file extension!\n",
    "        dir_path\n",
    "            >> the name(s) of the directory(s) that lead to the files to be archived\n",
    "            are located\n",
    "        ----\n",
    "    Returns\n",
    "        ----\n",
    "        Creates a gzipped tar archive in the currnt working directory.\n",
    "        ----\n",
    "    Versioning\n",
    "        ----\n",
    "        Python: 3.10.9\n",
    "        tarfile included in Python version\n",
    "        ----\n",
    "    \n",
    "    \"\"\"\n",
    "    import tarfile\n",
    "    tar = tarfile.open(f\"{tar_name}.tar.gz\", \"w:gz\")\n",
    "    for file in files:\n",
    "        if folder_name != \"\":\n",
    "            file_path = f\"{dir_path}/{file}\"\n",
    "        else:\n",
    "            file_path = file\n",
    "        tar.add(file_path)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11d6f240-c99f-480c-9592-f3d54840fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"hancock.dbf\", \"hancock.shp\", \"hancock.shx\"]\n",
    "tar_name = \"hancock\"\n",
    "folder_name = \"hancock\"\n",
    "files_to_tar_gz(files, tar_name, folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
